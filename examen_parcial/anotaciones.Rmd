---
title: "Anotaciones Examen Parcial"
author: "Jesus Mauricio Huayhua Flores"
date: "2024-05-12"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Librerias

```R
library(DescTools)
library(ggplot2)
library(MASS)
```

# Lectura de archivos

```R
# Para leer archivos xlsx
data <- read_xlsx(path="directory/file.xlsx")
head(data)
# Para leer archivos csv
data <- read.csv("directory/file.csv")
```

# Pruebas de bondad de ajuste

## Distribución multinominal

- Repetir n veces, de forma independiente
- $k(k \geqslant 2)$ resultados o categorias
- $C_1, C_2, \dots, C_k$ con $p_1,p_2,\dots,p_k$
- $\sum_{i = 1}^{k}p_i = 1$
- Notación: $(X_1,X_2,\dots,X_k)\sim Mult(n,p_1,p_2,\dots,p_k)$

### Función de probabilidad conjunta

Si $(X_1,X_2,\dots,X_k)\sim Mult(n,p_1,p_2,\dots,p_k)$

$$
P(X_1=x_1,\dots,X_k=x_k) = \frac{n!}{x_1!\dots x_k!} p_{1}^{x_1}\dots p_{k}^{x_k}
$$
- $X_1,X_2,\dots,X_k$ **NO** son independientes
- $X_1 \sim B(n,p_i), \forall i = 1, \dots,k$
- $E(X_i) = np_i$
- $V(X_i) = np_i(1 - p_i)$
- $Cov(X_i,X_j) = -np_ip_j,\text(si)\ i\neq j$


## Pruebas Chi-cuadrado

Utilizado para contrastar hipótesis acerca de los parámetros, de 1 o varias distribuciones multinominales.

$$
W=\sum_{i = 1}^{k}\frac{(X_i - E_i)^2}{E_i}
$$

### Teorema 1

Si **n** es grande, $\forall i = 1,\dots,k$ se cumple que $E_i = np_i \geqslant 5$

$$
W=\sum_{i = 1}^{k}\frac{(X_i - E_i)^2}{E_i} = \sum_{i = 1}^{k}\frac{(X_i - np_i)^2}{np_i}
$$

Tiene distribución Chi-cuadrado con (K - 1) grados de libertad $W \sim X_{(k - 1)}^2$


## Prueba Chi-cuadrado para bondad de ajuste

Es la prueba para determinar si la variable que observamos se ajusta o no a una distribución teórica.

$$
\begin{cases}
H_0 :& F_Y = F_o\\
H_1 :& F_Y \neq F_o
\end{cases}
$$

Experimento multinominal de *k* categorías excluyentes.

- $C_1,\dots,C_k$ con probablidades $p_1,\dots,p_k$

- Frecuencias observadas $x_1,\dots,x_2$, donde $\sum_{i=1}^{k}x_i = n$

- $X_i$ números de veces en que ocurre la categoría $C_i$

- Contrastar si las frecuencias observadas de cada categoría difieren significativamente, de las frecuencias esperadas $e_i = np_i$

$$
\begin{cases}
H_0:& \forall i: p_i = p_i^o\\
H_1:& \exists i | p_i \neq p_i^o
\end{cases}
$$

Si $e_i = np_i^0 \geqslant 5$, la estadística de prueba:

$$
W=\sum_{i=1}^{k} \frac{(X_i - np_i^0)^2}{np_i^0} = \sum_{i=1}^{k} \frac{(O_i - e_i^0)^2}{ei}
$$

Punto crítico, se distribuye Chi-cuadrado con $k-1$ grados de libertad: $W\sim X_{k-1}^2$.


# Pasos para la prueba de Chi-cuadrado(x^2) de bondad de ajuste

1. Establecer las hipótesis sobre la función de distribución desconocida

$$
\begin{cases}
H_0 &: F_Y = F_0 \\
H_1 &: F_Y \neq F_0
\end{cases}, con\ F_0\ conocida
$$


2. Obtener una tabla aleatoria de tamaño **n** de *Y*, con una tabla de distribución de frecuencias.

```
| Intervalos | marca de clase | frecuencia observada | frecuencia esperada |
```


3. Se calculan las frecuencias esperadas $E_i^0$

4. Se calcula Estadístico de prueba

$$
U_0 = \sum_{i = 1}^{k}\frac{(O_i - E_i^0)^2}{E_i^0} \sim X_(k -m-1)^2
$$

5. Se recha si $U_0 > X_{1-\alpha,k-m-1}^{2}$, donde $r$ es la cantidad de parametros desconocidos.


## Comandos utilices en R

![](img/shapiro_test.png)


# Pruebas no paramétricas

Los investigadores están más familiarizados con las pruebas paramétricas, estas tienen supuestos usualmente acerca del tipo de variables y la distribución de la variable, los cuales tiene que ser verificados y en caso no cumplas los supuestos, utilizar pruebas no paramétricas.



## Prueba Wilcoxon

### Utilidad

Evaluación de la medida de posición de una muestra.

No se requiere de ningún supuesto acerca de la forma de la distribución de la población.


- $H_0: Me = Me_0$

### Procedimiento

Diferencia entre cada valor observado y el valor hipotético de la mediana.

$$
d = (X - med_0)
$$
Calculamos al diferencia sin tomar el signo de las mismas.

En caso de empate, se asigna un rango promedio de todas las diferencias empatadas.


La suma de rangos positivos $S^+$ es el estadístico de prueba, el cual es comparado con un valor de la talba de Wilcoxon

Forma práctica, se enumar de menor a mayor diferencia, y posteriormente se verifica en cuantos se encuentra empate en la diferencia para posteriormente realizar el promedio de las diferencias de dichos valores


# En R

```
wilcox.test(data, mu = , alternative = "greater",conf.level = 1 - alpha, correct = F)
```

















































